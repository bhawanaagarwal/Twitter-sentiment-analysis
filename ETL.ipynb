{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63327603",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ed9ed8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import preprocessor as p\n",
    "import emojis\n",
    "import re\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "56aa0f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "slang = {'luv':'love','wud':'would','lyk':'like','wateva':'whatever','ttyl':'talk to you later', 'rip':'rest in peace','kul':'cool','fyn':'fine','omg':'oh my god',\n",
    "'fam':'family','bruh':'brother', 'bro':'brother','cud':'could','fud':'food','btw':'by the way',\"can't\":'cannot',\"cant\":\"cannot\",\"shouldn't\":\"should not\",\n",
    "\"shouldnt\":\"should not\",\"couldn't\":\"could not\",\"couldnt\":\"could not\"}\n",
    "\n",
    "SMILEYS = {\":‑(\":\"sad\", \":‑(\":\"sad\", \":(\":\"sad\",\":‑c\":\"sad\",\":c\":\"sad\",\":‑<\":\"sad\",\":<\":\"sad\",\":‑[\":\"sad\",\":[\":\"sad\",\":-||\":\"sad\",\">:[\":\"sad\",\":{\":\"sad\",\":@\":\"sad\",\":(\t\":\"sad\",\";( \":\"sad\",\":‑)\":\"happy\", \":‑D\" : \"laughing\", \"8D\":\"laughing\" , \"x‑D\": \"laughing\", \"xD\": \"laughing\",\"X‑D\": \"laughing\",\n",
    "\"XD\": \"laughing\",\"=D\": \"laughing\", \"=3\": \"laughing\", \"B^D\": \"laughing\" , \"c:\" : \"laughing\", \":-]\":\"happy\",\":]\": \"happy\",\":-3\": \"happy\", \":3\":\"happy\", \":->\": \"happy\",\":>\": \"happy\", \"8-)\": \"happy\",\"8)\": \"happy\",\":-}\": \"happy\",\":}\": \"happy\",\":o)\": \"happy\",\":c\": \"happy\" , \":^)\": \"happy\",\"=]\": \"happy\", \"=)\": \"happy\",\n",
    "\":‑###..\":\"being sick\",\":###..\":\"being sick\",\"',:-|\":\"disbelief\",\"',:-l\":\"disbelief\",\">:‑)\":\"Evil\",\"}:‑)\":\"Evil\",\"}:)\":\"Evil\",\"3:‑)\":\"Evil\",\"3:)\":\"Evil\",\">;)\":\"Evil\",\";3\":\"Evil\",\"D‑':\":\"horror\"}\n",
    "\n",
    "\n",
    "def convert_emojis(text):\n",
    "    text = emojis.decode(text)\n",
    "    text = text.replace(\":\",\" \")\n",
    "    text  = ' '.join(text.split())\n",
    "\n",
    "    return text\n",
    "\n",
    "def convert_emoticons(text):\n",
    "    words = text.split()\n",
    "    words = [SMILEYS[word] if word in SMILEYS else word for word in words]\n",
    "    text = \" \".join(words)\n",
    "    return text \n",
    "\n",
    "def correction(text):\n",
    "    words = text.split()\n",
    "    words = [slang[word] if word in slang else word for word in words]\n",
    "    text = \" \".join(words)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "21ebdc7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ETL():\n",
    "    \n",
    "    def __init__(self,twitter_data,Filepath):\n",
    "        \n",
    "        #assigning twitter data a variable\n",
    "        self.twitter_data = twitter_data\n",
    "        \n",
    "        #assigning data variable \n",
    "        self.data = pd.read_csv(twitter_data)\n",
    "        \n",
    "        #location of saving preprocessed data\n",
    "        self.Filepath = Filepath\n",
    "        \n",
    "        \n",
    "    # loading data    \n",
    "    def load_data(self):\n",
    "\n",
    "        #print the dataset shape\n",
    "        print('The number of tweets:\\n{}\\n\\n'.format(self.data.shape[0]))\n",
    "\n",
    "        #the feature of the data set are\n",
    "        print('The features or columns in our dataset are {}'.format(list(self.data.columns)))\n",
    "    \n",
    "    # Data analysis\n",
    "    def analysis(self):    \n",
    "        \n",
    "        self.plot_barchart()\n",
    "    \n",
    "        #Print the number of tweets with hate language\n",
    "        print('The number of hate tweets:\\n{}\\n\\n'.format(self.data[self.data['label'] == 1].shape[0]))\n",
    "\n",
    "        #the percentage of tweets with hate language\n",
    "        print('The percentage of hate tweets:\\n{}\\n\\n'.format((self.data[self.data['label']==1].shape[0]/self.data.shape[0])*100))\n",
    "\n",
    "        #print the number of tweets without hate language\n",
    "        print('The number of tweets not classified as hate tweets:\\n{}\\n\\n'.format(self.data[self.data['label']==0].shape[0]))\n",
    "\n",
    "        #the percentage of tweets without hate language\n",
    "        print('The percentage of tweets without hate language:\\n{}\\n\\n'.format((self.data[self.data['label']==0].shape[0]/self.data.shape[0])*100))\n",
    "        \n",
    "    \n",
    "    def data_cleaning(self):\n",
    "\n",
    "        #removing null labels\n",
    "        self.data = self.data[~self.data['label'].isnull()]\n",
    "        print('The number of data point remaining after removing all null labels:\\n{}\\n\\n'.format(self.data.shape[0]))\n",
    "\n",
    "        #removing duplicate tweets\n",
    "        self.data = self.data[~self.data['tweet'].duplicated()]\n",
    "        print('The number of data point remaning after removing all duplicate tweets:\\n{}\\n\\n'.format(self.data.shape[0]))\n",
    "\n",
    "        #cleaning the remaning data according to our needs\n",
    "        for i in self.data.index:    \n",
    "            tweet = \"\"\n",
    "            \n",
    "            #removing the urls and \n",
    "            p.set_options(p.OPT.URL)\n",
    "            tweet = p.clean(self.data['tweet'].loc[i])\n",
    "            \n",
    "            #conversion of emojis\n",
    "            tweet = convert_emojis(tweet)\n",
    "\n",
    "            #conversion of emoticons\n",
    "            tweet = convert_emoticons(tweet)\n",
    "            \n",
    "            #removing punctuations\n",
    "            tweet = ' '.join(re.sub(\"[#\\.\\,\\!\\?\\:\\;\\-\\=]\", \" \", tweet).split())\n",
    "            \n",
    "            #correcting slangs and misspells\n",
    "            tweet = correction(tweet)\n",
    "\n",
    "            #removing the remaining emoticons and numbers data in text\n",
    "            p.set_options(p.OPT.MENTION,p.OPT.HASHTAG,p.OPT.RESERVED,p.OPT.EMOJI,p.OPT.SMILEY,p.OPT.NUMBER)\n",
    "            tweet = p.clean(tweet)\n",
    "\n",
    "            self.data['tweet'].loc[i] = tweet\n",
    "            \n",
    "        for index,rows in self.data.iterrows():\n",
    "            strng = \"\"\n",
    "            for words in rows['tweet'].split():\n",
    "\n",
    "                #removing special characters \n",
    "                word = (\"\".join(i for i in words if i.isalnum()))\n",
    "\n",
    "                #lowering the words\n",
    "                word = word.lower()\n",
    "                \n",
    "                strng += word + \" \"\n",
    "\n",
    "            self.data['tweet'].loc[index] = strng\n",
    "        \n",
    "        \n",
    "        #printing the processed tweet\n",
    "        print('The tweet text data is processed{}'.format(self.data['tweet']))\n",
    "    \n",
    "    def save_data(self):\n",
    "\n",
    "        #saving data in a pickle file\n",
    "        self.data.to_pickle(self.Filepath)\n",
    "\n",
    "    def data_transform(self):\n",
    "    \n",
    "        print('LOADING DATA...{}\\n\\n '.format(self.twitter_data))\n",
    "        self.load_data()\n",
    "\n",
    "        print('DATA ANALYSIS...\\n\\n')\n",
    "        self.analysis()\n",
    "\n",
    "        print('CLEANING DATA...\\n\\n')\n",
    "        self.data_cleaning()\n",
    "        \n",
    "        self.plot_hate_normal_tweets()\n",
    "        \n",
    "        print('SAVING DATA IN PICKLE FILE PREPROCESSED {}...\\n\\n'.format(self.Filepath))\n",
    "        self.save_data()\n",
    "        \n",
    "        print('Cleaned data saved to pickle file preprocessed in Pickle folder')\n",
    "        \n",
    "        \n",
    "        \n",
    "    def plot_hate_normal_tweets(self):\n",
    "        fig, axs = plt.subplots(1,2 , figsize=(16,8))\n",
    "        text_pos = \" \".join(self.data['tweet'][self.data.label == 0])\n",
    "        text_neg = \" \".join(self.data['tweet'][self.data.label == 1])\n",
    "        train_cloud_pos = WordCloud(collocations = False, background_color = 'white').generate(text_pos)\n",
    "        train_cloud_neg = WordCloud(collocations = False, background_color = 'black').generate(text_neg)\n",
    "        axs[0].imshow(train_cloud_pos, interpolation='bilinear')\n",
    "        axs[0].axis('off')\n",
    "        axs[0].set_title('Non-Hate Comments')\n",
    "        axs[1].imshow(train_cloud_neg, interpolation='bilinear')\n",
    "        axs[1].axis('off')\n",
    "        axs[1].set_title('Hate Comments')\n",
    "\n",
    "        plt.show()\n",
    "        \n",
    "    def plot_barchart(self):        \n",
    "        fig2 = sns.countplot(x= 'label',data = self.data)\n",
    "        plt.title('Label Counts')\n",
    "        plt.xticks([0,1],['Hate', 'Normal'])\n",
    "        plot = fig2.get_figure()\n",
    "        plot.savefig('Count Plot.png')\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
